{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSLS-II: Image segmentation workflow example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as a general illustration of the steps and tools required in order to segment three-dimensional image data sets for quantitative analysis. \n",
    "\n",
    "The demonstration steps through a sample segmentation workflow, specific to x-ray tomography, and is broken down into each of the intermediate steps required: from \"raw\" collected image to quantified values and parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample data sets consist of micro-CT volumes collected using a single glass bead packed column.\n",
    "\n",
    "The final quantified product in this demonstration includes:\n",
    "- Solid volume (total volume of the beads)\n",
    "- Measured porosity\n",
    "- Surface area\n",
    "- Curvature\n",
    "- Solid grain size distribution (comparison of the volume and surface area of the individual beads in the column section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Dependencies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major python packages that are utilized in order to provide image processing functionality, quantification, and visualization include:\n",
    "+ Reconstruction\n",
    "  - tomopy\n",
    "+ Registration\n",
    "  - SimpleITK\n",
    "+ Analysis:\n",
    "  - Numpy\n",
    "  - Scikit-Image\n",
    "  - Scikit-Xray\n",
    "  \n",
    "+ Visualization:\n",
    "  - Summary Tables\n",
    "    - Pandas\n",
    "  - Two-dimensional Visualization\n",
    "    - Xray-vision\n",
    "    - Matplotlib\n",
    "    - Pyqtgraph\n",
    "  - Three-dimensional Visualization\n",
    "    - VTK\n",
    "    - MayaVI\n",
    "    - Pyqtgraph\n",
    "\n",
    "These packages are imported here for common use throughout the demonstration.\n",
    "\n",
    "An equivalent and parallel demonstration, using VisTrails, is provided to illustrate how to conduct the same operations using the VisTrails workflow and provanance manager."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the current implementation both mayavi and xray-vision must be imported first, in order to prevent conflicts with default settings associated with direct import of matplotlib.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:traits.has_traits:DEPRECATED: traits.has_traits.wrapped_class, 'the 'implements' class advisor has been deprecated. Use the 'provides' class decorator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "WARNING: Imported VTK version (6.2) does not match the one used\n",
      "         to build the TVTK classes (5.1). This may cause problems.\n",
      "         Please rebuild TVTK.\n",
      "********************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sip\n",
    "sip.setapi('QString', 2)\n",
    "import mayavi.mlab as mlab\n",
    "from xray_vision.mpl_plotting.img_proc_tools import plot_multiple_dsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# File I/O\n",
    "#from skxray import io\n",
    "from vttools.to_wrap.image.io import read_tiff\n",
    "#import pims\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tomographic reconstruction\n",
    "import tomopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image segmentation, analysis and quantification\n",
    "import numpy as np\n",
    "#import scipy as sp\n",
    "import skxray\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One particularly nice feature of iPython Notebook is the ability to have graphical results be plotted inline with the text and code that comprise this demonstration. In order to enable inline plotting using matplotlib\n",
    "\n",
    "```python\n",
    "%matplotlib inline\n",
    "```\n",
    "\n",
    "is included as a 'magic' function prior to the import string for matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting and visualization tools\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"backend\"] = \"Qt4Agg\"\n",
    "import matplotlib.pyplot as plt\n",
    "import pyqtgraph as pqg\n",
    "import vtk\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add reconstruction information and example here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING TOMOPY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of camera files associated with the data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note there are three .SPE camera files associated with each data set. The data was collected as part of a biofilm growth experiment conducted in collaboration with Dorthe Wildenschild. Imaging was conducted at the Advanced Photon Source, Argonne National Laboratory, Sector 13, BM-D.\n",
    "\n",
    "The data was collected in March of 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_cam_files = \"../data/mCT/camera_files/\"\n",
    "cam_fname_abv = ['biofilm_abv_cam_1.SPE', 'biofilm_abv_cam_2.SPE', 'biofilm_abv_cam_3.SPE']\n",
    "cam_fname_blw = ['biofilm_blw_cam_1.SPE', 'biofilm_blw_cam_2.SPE', 'biofilm_blw_cam_3.SPE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw camera (SPE) data for reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tomopy.io.reader:unknown file extension\n",
      "ERROR:tomopy.io.reader:unknown file extension\n",
      "ERROR:tomopy.io.reader:unknown file extension\n",
      "ERROR:tomopy.io.reader:unknown file extension\n",
      "ERROR:tomopy.io.reader:unknown file extension\n",
      "ERROR:tomopy.io.reader:unknown file extension\n"
     ]
    }
   ],
   "source": [
    "camfile_abv = []\n",
    "camfile_blw = []\n",
    "cam_lst = [camfile_abv, camfile_blw]\n",
    "for index, dset_list in enumerate([cam_fname_abv, cam_fname_blw]):\n",
    "    for fname in dset_list:\n",
    "        cam_lst[index].append(tomopy.read_aps_13bm(path_cam_files + fname, 'spe'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cam_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cam_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cam_lst[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_spe in module tomopy.io.reader:\n",
      "\n",
      "read_spe(fname, slc=None)\n",
      "    Read data from spe file.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    fname : str\n",
      "        String defining the path or file name.\n",
      "    slc : {sequence, int}\n",
      "        Range of values for slicing data.\n",
      "        ((start_1, end_1, step_1), ... , (start_N, end_N, step_N))\n",
      "        defines slicing parameters for each axis of the data matrix.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    ndarray\n",
      "        Data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tomopy.read_spe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_aps_13bm in module tomopy.io.exchange:\n",
      "\n",
      "read_aps_13bm(fname, format, proj=None, sino=None)\n",
      "    Read APS 13-BM standard data format.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    fname : str\n",
      "        Path to hdf5 file.\n",
      "    \n",
      "    format : str\n",
      "        Data format. 'spe' or 'netcdf4'\n",
      "    \n",
      "    proj : {sequence, int}, optional\n",
      "        Specify projections to read. (start, end, step)\n",
      "    \n",
      "    sino : {sequence, int}, optional\n",
      "        Specify sinograms to read. (start, end, step)\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    ndarray\n",
      "        3D tomographic data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tomopy.read_aps_13bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function find_center in module tomopy.recon.rotation:\n",
      "\n",
      "find_center(tomo, theta, ind=None, emission=True, init=None, tol=0.5, mask=True, ratio=1.0)\n",
      "    Find rotation axis location.\n",
      "    \n",
      "    The function exploits systematic artifacts in reconstructed images\n",
      "    due to shifts in the rotation center. It uses image entropy\n",
      "    as the error metric and ''Nelder-Mead'' routine (of the scipy\n",
      "    optimization module) as the optimizer :cite:`Donath:06`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    tomo : ndarray\n",
      "        3D tomographic data.\n",
      "    theta : array\n",
      "        Projection angles in radian.\n",
      "    ind : int, optional\n",
      "        Index of the slice to be used for reconstruction.\n",
      "    emission : bool, optional\n",
      "        Determines whether data is emission or transmission type.\n",
      "    init : float\n",
      "        Initial guess for the center.\n",
      "    tol : scalar\n",
      "        Desired sub-pixel accuracy.\n",
      "    mask : bool, optional\n",
      "        If ``True``, apply a circular mask to the reconstructed image to\n",
      "        limit the analysis into a circular region.\n",
      "    ratio : float, optional\n",
      "        The ratio of the radius of the circular mask to the edge of the\n",
      "        reconstructed image.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    float\n",
      "        Rotation axis location.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tomopy.find_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recon_abv = tomopy.find_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4095"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camfile_abv\n",
    "np.amax(camfile_abv[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Above and Below Edge volumes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module: PIMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vol_abv = pims.TiffStack(fname_abv)\n",
    "#vol_blw = pims.TiffStack(fname_blw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This module contains functions and tools for reading, writing and converting common image processing files and file types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = \"../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fname_abv_tiff = data_path + \"uCT/NSLS_shale_smpl-2_AbvFe.tiff\"\n",
    "fname_blw_tiff = data_path + \"uCT/NSLS_shale_smpl-2_BlwFe.tiff\"\n",
    "fname_abv = data_path + \"mCT/biofilm_33pcntBa__A_recon.volume\"\n",
    "fname_blw = data_path + \"mCT/biofilm_33pcntBa__B_recon.volume\"\n",
    "fname_bdpack = data_path + \"mCT/dry_beadpack_A_recon.volume\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls ../data/uCT/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tst = read_tiff(fname_blw_tiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fnames = [fname_abv, fname_blw, fname_bdpack]\n",
    "#for index, var in enumerate(fnames):\n",
    "#    print index\n",
    "#    print var\n",
    "header_abv, vol_abv = io.net_cdf_io.load_netCDF(fname_abv)\n",
    "header_blw, vol_blw = io.net_cdf_io.load_netCDF(fname_blw)\n",
    "header_dry, vol_dry = io.net_cdf_io.load_netCDF(fname_bdpack)\n",
    "\n",
    "print \"Array Max Value: \" + str(np.max(vol_abv))\n",
    "print \"Array Min Value: \" + str(np.min(vol_abv))\n",
    "#print header_dict_abv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample netCDF header\n",
    "The header in these netCDF files retains important information pertinent to not only the data set, but also to how the data set was collected.\n",
    "\n",
    "### Header Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print header_blw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Select how many of the available volumes to load\n",
    "num_vols = 3 # Length of the data list, dummy.\n",
    "axis = \"XY\"\n",
    "height = None\n",
    "num_columns = None\n",
    "#Input Lists\n",
    "sample_data = [vol_abv, vol_blw, vol_dry]\n",
    "plot_titles = [\"Bead pack sample: above Ba edge\", \"Bead pack sample: below Ba edge\", \"Bead pack sample: Dry column\"]\n",
    "#Error: If other than XY selected and data is only 2D array, then raise error pointing this out.\n",
    "plot_multiple_dsets (sample_data, 450, plot_titles, \"YZ\", num_columns=1)\n",
    "\n",
    "    # if plot_titles=None:\n",
    "        # for -- create for loop to generate list of str with (Dataset # 'index': 'dset variable name')\n",
    "#for x in range(num_vols):\n",
    "#    plt.figure(figsize = (5,(5.25*num_vols)))\n",
    "#    num_rows = num_vols\n",
    "#    num_columns = 1\n",
    "#    plt.subplot(((num_rows * 10 + num_columns) * 10 + (x+1)))\n",
    "#    plt.imshow(sample_data[x][:,450,:], cmap=plt.cm.gray)\n",
    "#    plt.title(plot_titles[x])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def auto_plot (num_figs, num_rows, num_cols, src_data_list, title_list=None, indi_figSize = None, display_slc=None):\n",
    "    if indi_figSize == None:\n",
    "        figsize = 5\n",
    "    else:\n",
    "        figsize = indi_figSize\n",
    "    \n",
    "    plt.figure(figsize = ((figsize*num_cols),(figsize*num_rows)))\n",
    "    for x in range(len(src_data_list)):\n",
    "        sample_data = src_data_list[x]\n",
    "        if len(sample_data.shape) == 2:\n",
    "            slc = sample_data[x][:,:]\n",
    "        elif len(sample_data.shape) == 3 and display_slc == None:\n",
    "            slc = sample_data[x][int(sample_data.shape[0]/2),:,:]\n",
    "        elif len(sample_data.shape) == 3 and display_slc != None:\n",
    "            slc = sample_data[x][int(display_slc),:,:]\n",
    "        plt.subplot(((num_rows * 10 + num_columns) * 10 + (x+1)))\n",
    "    plt.imshow(slc, cmap=plt.cm.gray)\n",
    "    plt.title(title_list[x])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Volume transformation to correct alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Packages: vttools.to_wrap.image.transformation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This module contains tools for basic spatial transformation of image volumes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The tools currently included in this module are:\n",
    "    + swap_axes\n",
    "    + flip_axis\n",
    "    + crop_volume\n",
    "    + rotate_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vttools.to_wrap.image import transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The z-axis orientation for all three of the volumes loaded as part of this demonstration is flipped. A problem that isn't necessarily an issue unless spatial orientation is important in the data analysis (e.g. when looking at sequential tiles in a single experimental sample, or when looking at spatial changes in a material over the course of an experiment). As a result, the data sets need to be flipped along the z-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corrected_src_data = []\n",
    "for x in sample_data:\n",
    "    xForm_vol = transformation.flip_axis(x, \"Flip Z\")\n",
    "    corrected_src_data.append(xForm_vol)\n",
    "num_rows=3\n",
    "num_cols=2\n",
    "plt.figure(figsize = ((5*num_cols),(5*num_rows)))\n",
    "for x in range(len(corrected_src_data)):\n",
    "    plt.subplot(((num_rows * 10 + (num_cols)) * 10 + 2*x+1))\n",
    "    plt.subplot(320+(x*2+1))\n",
    "    plt.imshow(sample_data[x][:,250,:], cmap=plt.cm.gray)\n",
    "    if x == 0:\n",
    "        plt.title('Original grayscale data')\n",
    "    plt.subplot(((num_rows * 10 + num_cols) * 10 + 2*x+2))\n",
    "    plt.imshow(corrected_src_data[x][:,250,:], cmap=plt.cm.gray)\n",
    "    if x == 0:\n",
    "        plt.title('Transformed grayscale data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Histogram analysis of trial volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module consists of a collection of functions specific to histogram visualization and analysis. A variety of options are included for both displaying and saving histogram data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module: histops.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from vttools.to_wrap.image import histogram\n",
    "from xray_vision.mpl_plotting.img_proc_tools import plot_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "num_cols = 2\n",
    "num_rows = 3\n",
    "#num_rows = num_vols\n",
    "\n",
    "num_bins = 1500\n",
    "pdf_hist = False\n",
    "plt.figure(figsize = ((5.5*num_cols),(5*num_rows)))\n",
    "plot_yscale = 'linear'\n",
    "for x in range(len(corrected_src_data)):\n",
    "    hist, bin_edges, bin_avg = histogram.hist_make(corrected_src_data[x], num_bins, pdf_hist)\n",
    "    \n",
    "    plot_min = np.amin(corrected_src_data[x])\n",
    "    plot_max = np.amax(corrected_src_data[x])    \n",
    "    plt.subplot(((num_rows * 10 + (num_cols)) * 10 + 2*x+1))\n",
    "    plt.subplot(320+(x*2+1))\n",
    "    plt.imshow(corrected_src_data[x][:,250,:], cmap=plt.cm.gray)\n",
    "    if x == 0:\n",
    "        plt.title('Transformed grayscale data')\n",
    "    plt.subplot(((num_rows * 10 + num_cols) * 10 + 2*x+2))\n",
    "    #plot_histogram(hist, bin_edges, plot_min, plot_max, plot_yscale)\n",
    "plt.show()\n",
    "print np.amin(hist)\n",
    "print np.amax(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Thresholding for trial volume segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module: threshops.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This module contains tools for thresholding image data."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Currently a number of tools are available for both manual and automatic thresholding.\n",
    "\n",
    "Manual:\n",
    "    Manual thresholding requires that threshold intensities be identified and explicitly stated\n",
    "    within the thresholding function call. The result will consist of a binary representation of \n",
    "    the original data set where all voxels, originally assinged an intensity value within the\n",
    "    specified boundary are assigned a value of 1 (True), and all voxels with intensity values\n",
    "    outside the specified bounds are assigned a value of 0 (False).\n",
    "    \n",
    "    Options for manual thresholding:\n",
    "        + Global thresholding [requires only one threshold value be specified]:\n",
    "            *thresh_globalGT() -- Greater than the specified value\n",
    "            *thresh_globalLT() -- Less than the specified value \n",
    "        + Bounded thresholding [requires two threshold values be specified]:\n",
    "            *thresh_bounded() -- Identifies all voxels with intensities within bounded region.\n",
    "                This method is useful for isolating specific peaks, or materials, within a single\n",
    "                data set -- termed multi-thresholding.\n",
    "Automatic:    \n",
    "    Options for automatic thresholding:\n",
    "        + Adaptive thresholding:\n",
    "            *thresh_adapt()\n",
    "        + Otsu method:\n",
    "            *thresh_otsu()\n",
    "        + Yen method:\n",
    "            *thresh_yen()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import threshops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Manual thresholding demonstration\n",
    "thresh_value = 1000\n",
    "\n",
    "solid_matrix = []\n",
    "\n",
    "for x in range(len(corrected_src_data)):\n",
    "    manual_result = threshops.thresh_globalGT(corrected_src_data[x], thresh_value)\n",
    "    solid_matrix.append(manual_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plotting manual thresholding results\n",
    "num_cols = 3\n",
    "num_rows = 3\n",
    "#num_rows = num_vols\n",
    "\n",
    "plt.figure(figsize = ((5.5*num_cols),(6*num_rows)))\n",
    "for x in range(len(corrected_src_data)):\n",
    "    hist, bin_edges, bin_avg = histops.hist_make(corrected_src_data[x], num_bins, pdf_hist)\n",
    "    thresh_coords_x = [thresh_value, thresh_value]\n",
    "    thresh_coords_y = [np.amin(hist), np.amax(hist)]\n",
    "    plot_min = np.amin(corrected_src_data[x])\n",
    "    plot_max = np.amax(corrected_src_data[x])    \n",
    "    \n",
    "    plt.subplot(((num_rows * 10 + num_cols) * 10 + num_cols*x+1))\n",
    "    plt.imshow(corrected_src_data[x][:,250,:], cmap=plt.cm.gray)\n",
    "    if x == 0:\n",
    "        plt.title('Transformed grayscale data')\n",
    "    \n",
    "    plt.subplot(((num_rows * 10 + num_cols) * 10 + num_cols*x+2))\n",
    "    histops.hist_plot(hist, bin_edges, plot_min, plot_max, plot_yscale, 'No')\n",
    "    plt.plot(thresh_coords_x, thresh_coords_y, color='r')\n",
    "    plt.annotate('threshold marker', \n",
    "                 xy=(thresh_value, (np.amax(hist)*0.7)), \n",
    "                 xytext=((thresh_value+750), np.amax(hist)*0.95),\n",
    "                 arrowprops=dict(facecolor='red', shrink=0.05)\n",
    "                 )\n",
    "    plt.subplot(((num_rows * 10 + num_cols) * 10 + num_cols*x+3))\n",
    "    plt.imshow(solid_matrix[x][:,250,:], cmap=plt.cm.gray)\n",
    "    if x == 0:\n",
    "        plt.title('Binary result from thresholding')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Automatic thresholding demonstration\n",
    "auto_adapt_solid = []\n",
    "auto_otsu_solid = []\n",
    "auto_yen_solid = []\n",
    "\n",
    "\n",
    "for x in range(len(corrected_src_data)):\n",
    "    \n",
    "    adapt_block_size = 250\n",
    "    adapt_thresh = threshops.thresh_adapt(corrected_src_data[x], adapt_block_size)\n",
    "    auto_adapt_solid.append(adapt_thresh)\n",
    "    \n",
    "    otsu_thresh_trial, otsu_T_value = threshops.thresh_otsu(corrected_src_data[x])\n",
    "    auto_otsu_solid.append(otsu_thresh_trial)\n",
    "    \n",
    "    yen_thresh_trial, yen_T_value = threshops.thresh_yen(corrected_src_data[x])\n",
    "    auto_yen_solid.append(yen_thresh_trial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(solid_matrix[0][:,250,:], cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "for x in range(num_vols):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plotting automatic thresholding results\n",
    "num_cols = 6\n",
    "num_rows = 3\n",
    "#num_rows = num_vols\n",
    "\n",
    "plt.figure(figsize = ((5.5*num_cols),(6*num_rows)))\n",
    "for x in range(num_vols):\n",
    "    hist, bin_edges, bin_avg = histops.hist_make(corrected_src_data[x], num_bins, pdf_hist)\n",
    "    \n",
    "    thresh_type_labels = ['manual', 'Otsu', 'Yen']\n",
    "    label_offsets = [0.95, 0.8, 0.6]\n",
    "    thresh_coords_x = [[thresh_value, thresh_value], \n",
    "                       [otsu_T_value, otsu_T_value], \n",
    "                       [yen_T_value, yen_T_value]]\n",
    "    thresh_coords_y = [np.amin(hist), np.amax(hist)]\n",
    "    color_set_ = ['r', 'g', 'b']\n",
    "    \n",
    "    plot_min = np.amin(corrected_src_data[x])\n",
    "    plot_max = np.amax(corrected_src_data[x])    \n",
    "    \n",
    "    plt.subplot(((num_rows * 10 + num_cols) * 10 + num_cols*x+1))\n",
    "    plt.imshow(corrected_src_data[x][:,250,:], cmap=plt.cm.gray)\n",
    "    if x == 0:\n",
    "        plt.title('Transformed grayscale data')\n",
    "    \n",
    "    plt.subplot(((num_rows * 10 + num_cols) * 10 + num_cols*x+2))\n",
    "    histops.hist_plot(hist, bin_edges, plot_min, plot_max, plot_yscale, 'No')\n",
    "    for y in range(len(thresh_type_labels)):\n",
    "        plt.plot(thresh_coords_x[y], thresh_coords_y, color=color_set_[y])\n",
    "        plt.annotate(thresh_type_labels[y], \n",
    "                     xy=(thresh_coords_x[y][0], (np.amax(hist)*0.7)),\n",
    "                     xytext=((thresh_coords_x[y][0]+750), np.amax(hist)*label_offsets[y]), \n",
    "                     arrowprops=dict(facecolor=color_set_[y], shrink=0.05))\n",
    "    plt.subplot(((num_rows * 10 + num_cols) * 10 + num_cols*x+3))\n",
    "    plt.imshow(solid_matrix[x][:,250,:], cmap=plt.cm.gray)\n",
    "    if x == 0:\n",
    "        plt.title('Binary result from manual thresholding')\n",
    "    plt.subplot(((num_rows * 10 + num_cols) * 10 + num_cols*x+4))\n",
    "    \n",
    "    plt.imshow(auto_adapt_solid[x][:,250,:], cmap=plt.cm.gray)\n",
    "    if x == 0:\n",
    "        plt.title('Binary result from Adaptive thresholding')\n",
    "    plt.subplot(((num_rows * 10 + num_cols) * 10 + num_cols*x+5))\n",
    "    plt.imshow(auto_otsu_solid[x][:,250,:], cmap=plt.cm.gray)\n",
    "    if x == 0:\n",
    "        plt.title('Binary result from Otsu thresholding')\n",
    "    plt.subplot(((num_rows * 10 + num_cols) * 10 + num_cols*x+6))\n",
    "    plt.imshow(auto_yen_solid[x][:,250,:], cmap=plt.cm.gray)\n",
    "    if x == 0:\n",
    "        plt.title('Binary result from Yen thresholding')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive thresholding: Block size evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ad_block_size = [5, 10, 20, 50, 100, 250]\n",
    "num_cols = 6\n",
    "num_rows = 3\n",
    "#num_rows = num_vols\n",
    "\n",
    "ad_test = []\n",
    "plt.figure(figsize = (((5.5*num_cols),(6*num_rows))))\n",
    "for x in range(len(corrected_src_data)):\n",
    "    for y in range(len(ad_block_size)):\n",
    "        tmp_binary = threshops.thresh_adapt(corrected_src_data[x], ad_block_size[y])\n",
    "        ad_test.append(tmp_binary)\n",
    "        if y == 0:\n",
    "            plt.subplot(((num_rows * 10 + num_cols) * 10 + num_cols*x+1))\n",
    "            plt.imshow(corrected_src_data[x][:,250,:], cmap=plt.cm.gray)\n",
    "            plt.title(\"Original Data\")\n",
    "        plt.subplot(((num_rows * 10 + num_cols) * 10 + num_cols*x+y+1))\n",
    "        plt.imshow(ad_test[y][:,250,:])\n",
    "        plt.title(\"Adaptive threshold: Block size = \" + str(ad_block_size[y]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Isolate pore space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module: mathops.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mathops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pore_space = []\n",
    "\n",
    "for x in range(len(solid_matrix)):\n",
    "    tmp_pore = np.logical_not(solid_matrix[x])\n",
    "    pore_space.append(tmp_pore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Generate exterior mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module: synth_drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import synth_drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "exterior_mask=synth_drawing.draw_cylinder(corrected_src_data[0], None, 325, None, None, 'YES')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masked volume demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask_demo=synth_drawing.draw_cylinder(corrected_src_data[0], \n",
    "                                      radius=325, \n",
    "                                      value = 2000, \n",
    "                                      draw_exterior='YES', \n",
    "                                      apply_mask='yes')\n",
    "\n",
    "plt.imshow(mask_demo[50,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolated phase presentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Glass beads: solid_matrix[0]\n",
    "#Pore space: pore_space[0]\n",
    "#exterior: exterior_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,4.5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(solid_matrix[0][50,:,:])\n",
    "plt.subplot(132)\n",
    "plt.imshow(pore_space[0][50,:,:])\n",
    "plt.subplot(133)\n",
    "plt.imshow(exterior_mask[50,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Merge materials and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import filterops as fltr\n",
    "import morphology as morph\n",
    "import scipy.ndimage.measurements as measure\n",
    "import mathops\n",
    "\n",
    "def logical_sub(src_data1, \n",
    "                src_data2):\n",
    "    temp = np.logical_not(np.logical_and(src_data1, \n",
    "                                         src_data2))\n",
    "    output = np.logical_and(src_data1, \n",
    "                            temp)\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rough quantification\n",
    "labels_rough = (exterior_mask) + (pore_space[0]) + (solid_matrix[0]*3)\n",
    "glass_bead_corrected = 3*(logical_sub(solid_matrix[0], exterior_mask))\n",
    "pore_space_corrected = 2*(logical_sub(pore_space[0], exterior_mask))\n",
    "\n",
    "#Merge volume:\n",
    "label_field = (exterior_mask + 2*pore_space_corrected + 3*glass_bead_corrected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_field_int = label_field.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(label_field_int[50,:,:], cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imgQuant\n",
    "\n",
    "measures, vol_rec = imgQuant.Q_VOL(label_field_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "bead_vol = measures['Material_4']['volume']['value']\n",
    "pore_sp_vol = measures['Material_1']['volume']['value']\n",
    "\n",
    "bead_vol_corrected = float(bead_vol) * 9.5**3\n",
    "pore_sp_vol_corrected = float(pore_sp_vol) * 9.5**3\n",
    "print \"Measured bead volume (um^3): \" + str(bead_vol_corrected)\n",
    "print \"Measured pore space (um^3): \" + str(pore_sp_vol_corrected)\n",
    "porosity = pore_sp_vol/(bead_vol+pore_sp_vol)\n",
    "print \"Measured column section porosity is: \" + str(porosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Volume confirmation:\n",
    "total_vol = bead_vol_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!gist \"NSLS-II Segmentation workflow design.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
